{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Numerical Linear Algebra/Eigenproblems (Prof. Peterson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ be an $n \\times n$ full rank matrix. We are interested in solving the linear system $Ax = B$ using an iterative method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Give reasons why you would choose to use an iterative method instead of a direct solver.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Iterative methods are often faster if we have a good initial guess. This occurs often when solving time dependent PDEs, where we can use the solution of the previous time step as the initial guess for the next time step.\n",
    "* Iterative methods often use less storage, in particular when dealing with sparse matrices. We only have to store the nonzero elements of sparse matrices. There are direct methods for sparse matrices as well, but they are more complicated than iterative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Let $x^0$ be given and consider the preconditioner form of an iterative method given by\n",
    "$$ x^{k+1} = x^k + Q^{-1} r_k, \\qquad k=0,1,2,... $$\n",
    "where $Q$ is an $n \\times n$ invertible matrix and $r_k$ is the residual\n",
    "$$ r_k = b - Ax^k $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) i) If $x^k$ converges to a vector $y$, prove that this vector is the unique solution to $Ax = b$. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x^k$ converges to $y$ means that $y$ satisfies the equation:\n",
    "$$y = y + Q^{-1}(b - Ay)$$\n",
    "$$0 = Q^{-1}(b - Ay)$$\n",
    "Since we have a product, and $Q^{-1}$ cannot be 0, then $(b - Ay) = 0$.\n",
    "Which implies $Ay = b$ and hence $y$ is the unique solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) ii) The motivation for this form of the iterative method can be seen by taking $Q = A$. In this case, what is $x^1$? What does this suggest we could choose for $Q$? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $Q = A$. Then our iterative method looks like:\n",
    "$$ x^{k+1} = x^k + A^{-1} (b-Ax^k)$$\n",
    "$$ x^{k+1} = x^k + A^{-1}b - A^{-1}Ax^k$$\n",
    "$$ x^{k+1} = A^{-1}b $$\n",
    "Our new method finds the solution within one iteration, so $x^1 = x$\n",
    "## What does this suggest we could choose for $Q$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Let $e_k = x^k - x$ be the error vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) i) Show that $e_k$ satisfies\n",
    "$$ e_k = B^k e_0 $$\n",
    "for an appropriately chosen matrix $B$; explicitly give $B$. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$e_{k+1} = x^{k+1} - x = x^k + Q^{-1}(b-Ax^k) - x - Q^{-1}(b-Ax)$$\n",
    "$$= x^k - x + Q^{-1}b - Q^{-1}Ax^k - Q^{-1}b + Q^{-1}Ax$$\n",
    "$$= x^k - x - Q^{-1}Ax^k + Q^{-1}Ax$$\n",
    "$$= x^k - x - Q^{-1}A(x^k - x)$$\n",
    "$$= (1-Q^{-1}A)(x^k - x)$$\n",
    "If we do this recursively we get\n",
    "$$(x^{k+1} - x) = (1-Q^{-1}A)^{k+1} (x^0 - x)$$\n",
    "If we set $B = (1-Q^{-1}A)$ then we've shown \n",
    "$e_{k+1} = B^{k+1}e_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) ii) Use your result in (i) to give a sufficient condition for convergence of the iterative method in (b) in terms of the norm of $B$. Justify your answer. Is this true for any matrix norm? Relate your answer in terms of the norm of $B$ to the eigenvaleus of $B$. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have\n",
    "$$ x^k - x = (1-Q^{-1}A)^k (x^0-x) $$\n",
    "Taking the norm of both sides we get\n",
    "$$ ||x^k - x|| = ||(1-Q^{-1}A)^k (x^0-x)|| $$\n",
    "$$ \\leq ||(1-Q^{-1}A)^k||\\quad ||x^0-x|| $$\n",
    "Since we want a condition for convergence, we take the limit of both sides as $k \\to \\infty$\n",
    "$$ \\lim_{k \\to \\infty} ||x^k - x|| \\leq \\lim_{k \\to \\infty} ||(1-Q^{-1}A)^k|| \\quad ||x^0-x|| $$\n",
    "Notice that $||x^0-x||$ is constant, so we only want $\\lim_{k \\to \\infty} ||(1-Q^{-1}A)^k|| = \\lim_{k \\to \\infty} ||B^k||$.\n",
    "Since $\\lim_{k \\to \\infty} e_k = 0$ we know $\\rho(B) < 1$ and we also know $\\rho(B) < ||B||$, so we have a criterion for convergence in terms of the norm of $B$. Also, because we did not use any property of norms that is specific to a particular norm, our result is true for all norms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) iii) Show that the residual $r_k$ satisfies\n",
    "$$ r_k = C^k r_0 $$\n",
    "for an appropriately chosen matrix $C$; Explicitly give $C$. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_{k+1} = b-Ax^{k+1} = b-A(x^k + Q^{-1}(b-Ax^k))$$\n",
    "$$ = b-Ax^k + AQ^{-1}(b-Ax^k)$$\n",
    "$$ = r_k + AQ^{-1}r_k $$\n",
    "$$ = (1 + AQ^{-1})r_k $$\n",
    "If we do this recursively we get\n",
    "$$r_{k+1} = (1 + AQ^{-1})^{k+1} r_0 $$\n",
    "So we set $C = (1 + AQ^{-1})$ and we've shown that\n",
    "$$r_{k+1} = C^{k+1} r_0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Write pseudo-code to efficiently implement the iterative method in **(b)** assuming you are given the matrix $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) i)  give the operation count for computing $p$ iterations if $Q$ is a full matrix.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** d) ii)  Give the operation count for computing $p$ iterations if $Q$ is a tridiagional matrix. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** e)  if B and C are similar matrices then explain how this effects the behaviour of $e_k$ and $r_k$ **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If B and C are similar matrices, they have the same eigenvalues. This means they have the same spectral radii, which implies they both converge (or both diverge). This is useful because in practice we don't have the true solution, so we can't calculate $e_k$. We can track $r_k$ and if $r_k$ converges, then we know $e_k$ also converges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
