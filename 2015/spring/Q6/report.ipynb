{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6\n",
    "solution from Chaolun\n",
    "\n",
    "##### 1)\n",
    "Denote the given data sample $D=(x_1,x_2....x_n)$. $\\mu$ and $\\sigma^2$ are the mean and varience of the data distribution separately. $\\mu_0$ and $\\sigma_0^2$ are the mean and varience of the prior distribution, $\\mu_n$ and $\\sigma_n^2$ are the mean and varience of the posterior distribution.\n",
    "\n",
    "The likelihood function takes the form of the distribution:\n",
    "$$\n",
    "p(D|\\mu,\\sigma)=(2\\pi\\sigma^2)^{-\\frac{n}{2}}e^{-\\frac{1}{2\\sigma^2}\\sum_i^n(x_i-\\mu)^2}\n",
    "$$\n",
    "If we define $\\bar{x}=\\frac{1}{n}\\sum_{i=1}^nx_i$, $s^2=\\frac{1}{n}\\sum_i^n(x_i-\\bar{x})^2$, the summating in the exponent above can be given as:\n",
    "$$\n",
    "\\sum_i(x_i-\\mu)^2=ns^2+(\\bar{x}-\\mu)^2\n",
    "$$\n",
    "So the likelihood function can be written as:\n",
    "$$\n",
    "p(D|\\mu,\\sigma)=\\frac{1}{(2\\pi)^{\\frac{n}{2}}}\\frac{1}{\\sigma^n}e^{-\\frac{1}{2\\sigma^2}ns^2+(\\bar{x}-\\mu)^2}\\\\\n",
    "\\propto (\\frac{1}{\\sigma^2})^{\\frac{n}{2}}e^{-\\frac{n}{2\\sigma^2}(\\bar{x}-\\mu)^2}e^{-\\frac{ns^2}{2\\sigma^2}}\n",
    "$$\n",
    "If we assume the variance of the sample is the same as its underlying distribution, which means $s=\\sigma$, we have:\n",
    "$$\n",
    "p(D|\\mu)\\propto e^{-\\frac{n}{2\\sigma^2}(\\bar{x}-\\mu)^2}\n",
    "$$\n",
    "The natural conjugate prior for this problem also takes the form of a normal distribution, as the Gaussian family is self-conjugate. So the prior distribution has the form:\n",
    "$$\n",
    "p(\\mu)\\propto e^{-\\frac{1}{2\\sigma_0^2}(\\mu-\\mu_0)^2}\n",
    "$$\n",
    "\n",
    " we can have:\n",
    "$$p(\\mu|D)\\propto p(D|\\mu)P(\\mu)\\propto  e^{-\\frac{n}{2\\sigma^2}(\\bar{x}-\\mu)^2-\\frac{1}{2\\sigma_0^2}(\\mu-\\mu_0)^2}$$\n",
    "The function above will be the posterior distribution of $\\mu$. This distribution  is also a Gaussian distribution:\n",
    "$$\\mu|D \\sim N(\\mu_n, \\sigma_n^2)$$\n",
    "The mean $\\mu_n$ will be the value of $\\mu$ which maximize the value of $p(\\mu|D)$, for continence I took the logarithm of $p(\\mu|D)$ as the function to be maximized, I can get:\n",
    "$$\\frac{\\partial log(p(\\mu|D))}{\\partial \\mu}=0$$\n",
    "Which gives:\n",
    "$$\\frac{n}{\\sigma^2}(\\bar{x}-\\mu)=\\frac{1}{\\sigma_0^2}(\\mu-\\mu_0)\n",
    "$$\n",
    "In this case the $\\mu$ will maximize the PDF, and it will be the mean $\\mu_n$:\n",
    "$$\\mu_n=\\frac{\\bar{x}n/\\sigma^2+\\mu_0/\\sigma_0^2}{1/\\sigma_0^2+n/\\sigma^2}$$\t\n",
    "The $\\sigma_n$ can be calculated by taking the second order partial derivative of PDF on $\\mu$. I got\n",
    "$$1/\\sigma_n^2=\\frac{\\partial^2 log(p(\\mu|D))}{\\partial \\mu^2}=1/\\sigma_0^2+n/\\sigma^2$$\n",
    "So I have:\n",
    "$$\\sigma_n=\\sqrt{\\frac{1}{1/\\sigma_0^2+n/\\sigma^2}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the given data D in the question, we have $\\bar{x}=18.09$ and $\\sigma=10.07$. If the prior distribution have $\\mu_0=15$ and $\\sigma_0=10$, we can have:$\\mu_n=17.8,\\sigma_n=3.03$. The calculation is as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the posterior mean: 17.806728\n",
      "the posterior standard deviation: 3.034327\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "D=[28.6864,26.4997,21.9809,32.2147,6.20551,1.57577,26.789,13.7372,15.0708,8.15355]\n",
    "n=10\n",
    "mu0=15\n",
    "sig0=10\n",
    "xb=np.average(D)\n",
    "sig=np.std(D)\n",
    "mun=(xb*n/sig/sig+mu0/sig0/sig0)/(1/sig0/sig0+n/sig/sig)\n",
    "print(\"the posterior mean: %f\"%mun)\n",
    "stdp=np.sqrt(1.0/(1/sig0/sig0+n/sig/sig))\n",
    "print(\"the posterior standard deviation: %f\"%stdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)\n",
    "It matters. The prior is the initial belef of the model, if the initial belef is very different from the distribution of the samples in D, the method will take more samples to converge. If the prior distribution have $\\mu_0=0$ and $\\sigma_0=1$, we can have:$\\mu_n=1.62,\\sigma_n=0.95$, which is much different than the result we got in 1), and the mean is much far away from the mean of the given sample. The calculation is as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the posterior mean: 1.623880\n",
      "the posterior standard deviation: 0.954065\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "D=[28.6864,26.4997,21.9809,32.2147,6.20551,1.57577,26.789,13.7372,15.0708,8.15355]\n",
    "n=10\n",
    "mu0=0\n",
    "sig0=1\n",
    "xb=np.average(D)\n",
    "sig=np.std(D)\n",
    "mun=(xb*n/sig/sig+mu0/sig0/sig0)/(1/sig0/sig0+n/sig/sig)\n",
    "print(\"the posterior mean: %f\"%mun)\n",
    "stdp=np.sqrt(1.0/(1/sig0/sig0+n/sig/sig))\n",
    "print(\"the posterior standard deviation: %f\"%stdp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
