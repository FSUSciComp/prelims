{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5\n",
    "solution from Chaolun\n",
    "\n",
    "##### 1\n",
    "According to the definition of likelyhood function, we have\n",
    "$$\n",
    "L(m,a)=P(Y|m,a)\\\\\n",
    "=\\prod_{i=1}^n P(Y_i|m,a) \\\\\n",
    "=(\\frac{1}{\\sqrt{2\\pi}\\sigma})^n \\prod_{i=1}^n exp(-\\frac{(Y_i-(X_i/a+sin(maX_i)))^2}{2\\sigma^2})\n",
    "$$\n",
    "\n",
    "##### 2\n",
    "From the likelyhood function above, we can write the cost function as:\n",
    "$$\n",
    "g(m,a)=\\sum_{i=1}^n(Y_i-(X_i/a+sin(maX_i)))^2\n",
    "$$\n",
    "so the objective of performing ML estimation of m, a is to find m, a which minimize the cost function g(m,a)\n",
    "\n",
    "Here we can use the gradient descent method to find the minimum, with:\n",
    "$$\n",
    "\\nabla g(m,a)=-\n",
    "   \\begin{bmatrix}\n",
    "   2\\sum_{i=1}^n (Y_i-(X_i/a+sin(maX_i)))(aX_icos(maX_i))\\\\\n",
    "   2\\sum_{i=1}^n (Y_i-(X_i/a+sin(maX_i)))(-\\frac{X_i}{a^2}+mX_icos(maX_i))\\\\\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m= 0.096274 a= 1.939750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient(x,y,m,a):\n",
    "    mnew=2*np.sum((y-(x/a+np.sin(m*a*x)))*(a*x*np.cos(m*a*x)))\n",
    "    anew=2*np.sum((y-(x/a+np.sin(m*a*x)))*(-1*x/a/a+m*x*np.cos(m*a*x)))\n",
    "    return (mnew,anew)\n",
    "\n",
    "x=np.linspace(1, 20, num=20)\n",
    "y=np.array([-0.3921, 2.6129, 2.4246, 2.4561, 3.7999, 3.2913, 6.2434, 5.2106, 5.6054, 3.8721, 6.5784, 6.8246, 8.1501, 8.5362, 7.7012, 8.6872, 8.5424, 10.0760, 8.7685, 9.1889])\n",
    "\n",
    "m=0.1\n",
    "a=2\n",
    "alf=0.00001\n",
    "\n",
    "for i in range(100000):\n",
    "    (dm,da)=gradient(x,y,m,a)\n",
    "    m=m+alf*dm\n",
    "    a=a+alf*da\n",
    "\n",
    "print(\"m= %f a= %f\"%(m,a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3\n",
    "The MAP can be evaluated by:\n",
    "$$\n",
    "P(m,a)*P(Y|m,a)=P(m)*P(a)*P(Y|m,a)\\\\\n",
    "=(\\frac{1}{\\sqrt{2\\pi}\\sigma})^n \\prod_{i=1}^n exp(-\\frac{(Y_i-(X_i/a+sin(maX_i)))^2}{2\\sigma^2})*\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(2-a)^2}{2\\sigma^2})*\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(0.1-m)^2}{2\\sigma^2})\n",
    "$$\n",
    "We can write the cost function as:\n",
    "$$\n",
    "g(m,a)=\\sum_{i=1}^n(Y_i-(X_i/a+sin(maX_i)))^2+(a-2)^2+(m-0.1)^2\n",
    "$$\n",
    "so the objective of performing ML estimation of m, a is to find m, a which minimize the cost function g(m,a)\n",
    "\n",
    "Here we can use the gradient descent method to find the minimum, with:\n",
    "$$\n",
    "\\nabla g(m,a)=-\n",
    "   \\begin{bmatrix}\n",
    "   2\\sum_{i=1}^n (Y_i-(X_i/a+sin(maX_i)))(aX_icos(maX_i))+2(0.1-m)\\\\\n",
    "   2\\sum_{i=1}^n (Y_i-(X_i/a+sin(maX_i)))(-\\frac{X_i}{a^2}+mX_icos(maX_i))+2(2-a)\\\\\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m= 0.096061 a= 1.940892\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient(x,y,m,a):\n",
    "    mnew=2*np.sum((y-(x/a+np.sin(m*a*x)))*(a*x*np.cos(m*a*x)))+2*(0.1-m)\n",
    "    anew=2*np.sum((y-(x/a+np.sin(m*a*x)))*(-1*x/a/a+m*x*np.cos(m*a*x)))+2*(2-a)\n",
    "    return (mnew,anew)\n",
    "\n",
    "x=np.linspace(1, 20, num=20)\n",
    "y=np.array([-0.3921, 2.6129, 2.4246, 2.4561, 3.7999, 3.2913, 6.2434, 5.2106, 5.6054, 3.8721, 6.5784, 6.8246, 8.1501, 8.5362, 7.7012, 8.6872, 8.5424, 10.0760, 8.7685, 9.1889])\n",
    "\n",
    "m=0.1\n",
    "a=2\n",
    "alf=0.00001\n",
    "\n",
    "for i in range(100000):\n",
    "    (dm,da)=gradient(x,y,m,a)\n",
    "    m=m+alf*dm\n",
    "    a=a+alf*da\n",
    "\n",
    "print(\"m= %f a= %f\"%(m,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4\n",
    "From bayesian theroem, we can have:\n",
    "$$\n",
    "P(m,a|Y)=P(Y|m,a)P(m,a)C\\\\\n",
    "=P(Y|m,a)P(m)P(a)C\\\\\n",
    "=\\prod_{i=1}^n exp(-\\frac{(Y_i-(X_i/a+sin(maX_i)))^2}{2\\sigma^2})*exp(-\\frac{(2-a)^2}{2\\sigma^2})*exp(-\\frac{(0.1-m)^2}{2\\sigma^2})C\n",
    "$$\n",
    "Where C is a constant, $\\sigma=1$.\n",
    "\n",
    "We know that:\n",
    "$$\n",
    "\\int_{m,a=-\\infty}^\\infty p(m,a|Y)=1\n",
    "$$\n",
    "also using the monte calo integration approach, we have:\n",
    "$$\n",
    "\\int_{m,a=-\\infty}^\\infty \\prod_{i=1}^n exp(-\\frac{(Y_i-(X_i/a+sin(maX_i)))^2}{2\\sigma^2})*exp(-\\frac{(2-a)^2}{2\\sigma^2})*exp(-\\frac{(0.1-m)^2}{2\\sigma^2})=1/12140342\n",
    "$$\n",
    "Which means $C=12140342$, thus we can write the posterior distribution of m,a as:\n",
    "$$\n",
    "P(m,a|Y)=\n",
    "=\\prod_{i=1}^n exp(-\\frac{(Y_i-(X_i/a+sin(maX_i)))^2}{2\\sigma^2})*exp(-\\frac{(2-a)^2}{2\\sigma^2})*exp(-\\frac{(0.1-m)^2}{2\\sigma^2})*12140342\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8237\n",
      "C= 12140342.357654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x,y,m,a):\n",
    "    return np.exp(-1*np.sum((y-(x/a+np.sin(m*a*x)))**2)/2)*np.exp(-0.5*(2-a)**2)*np.exp(-0.5*(0.1-m)**2)\n",
    "\n",
    "x=np.linspace(1, 20, num=20)\n",
    "y=np.array([-0.3921, 2.6129, 2.4246, 2.4561, 3.7999, 3.2913, 6.2434, 5.2106, 5.6054, 3.8721, 6.5784, 6.8246, 8.1501, 8.5362, 7.7012, 8.6872, 8.5424, 10.0760, 8.7685, 9.1889])\n",
    "\n",
    "sample=1000000\n",
    "count=0\n",
    "hight=0.0000001\n",
    "for i in range(sample):\n",
    "    m=np.random.uniform(-5,5)\n",
    "    a=np.random.uniform(-5,5)\n",
    "    h=np.random.uniform(0,hight)\n",
    "    if f(x,y,m,a)>h:\n",
    "        count=count+1\n",
    "res=hight*10*10*count/sample\n",
    "print(\"C= %f\"%(1/res))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
